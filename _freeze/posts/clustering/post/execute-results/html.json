{
  "hash": "5f5adafdef51912b1740e2d0bb472593",
  "result": {
    "markdown": "---\ntitle: 'Clustering'\nauthor: 'Shivangi Sarkar'\ndate: '2023-11-15'\ncategories: ['Clustering', 'Unsupervised learning']\ndescription: 'An introduction to clustering.'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n# What is clustering?\n\nClustering is an unsupervised learning method in machine learning. In unsupervised learning, the input data is unlabeled and it is therefore the machine learning model’s job to find correlation between the data points. Specifically, clustering divides a set of data points into groups, where in each group, the data points are similar in some aspect. Each of these groups is called a “cluster”.\n\n# Why do we need clustering?\n\nYou may be wondering why we need this method in the first place. Clustering is extremely useful in cases where the data present is not labeled.\n\n# What are the types of clustering?\n\nThe types of clustering methods are listed below:\n\n1. Centroid-based clustering: Organizes data into non-hierarchical clusters\n2. Density-based clustering: Connects areas of high densities into clusters\n3. Distribution-based clustering: Clusters data composed of distributions\n4. Hierarchical clustering: This method creates a tree of clusters\n\n# Real-world Applications\n\n### Listed below are the a few of the real world applications of clustering:\n\n* Cybersecurity: It can prevent cyberattacks by observing patterns of network traffic or system behavior\n* Crime analysis: Clustering can help to determine hotspots where criminal activity could occur, as well to predict future crime trends\n* Climate analysis: Clustering can allow us to observe and understand climate change as group patterns of weather conditions\n* Social network analysis: We can use clustering to group social networks users together based on similarities. This could in turn be used for targeted advertising and making content recommendations\n\n## Code Example\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Let's take a look at how K-means clustering can work on randomly generated data\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\nnp.random.seed(42)\n\nX= -2 * np.random.rand(100,2)\nX1 = 1 + 2 * np.random.rand(50,2)\nX[50:100, :] = X1\nplt.scatter(X[ : , 0], X[ :, 1], s = 50, c = 'b')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-2-output-1.png){width=569 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Now let's take those random data points and apply K-Means clustering to them\nkmeans = KMeans(n_clusters=2, random_state=42)\nkmeans.fit(X)\ncenters = kmeans.cluster_centers_\nlabels = kmeans.labels_\n\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=30, cmap='viridis', alpha=0.8)\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X', label='Cluster Centers')\nplt.title('K-Means Clustering Results')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-3-output-1.png){width=587 height=449}\n:::\n:::\n\n\n",
    "supporting": [
      "post_files"
    ],
    "filters": [],
    "includes": {}
  }
}