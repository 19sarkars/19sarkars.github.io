{
  "hash": "4e39e5311425c7d4c2a0dc73ad682300",
  "result": {
    "markdown": "---\ntitle: 'Classification'\nauthor: 'Shivangi Sarkar'\ndate: '2023-11-18'\ncategories: ['Classification', 'Supervised learning', 'Prediction']\ndescription: 'An introduction to classification in machine learning.'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n# What is classification?\n\nClassification is a machine learning method that relies on supervised learning (this is where the data is labeled). This task uses data to predict categories for an input. For example, an image could be shown to a model and it could categorize the image as either a cat or dog.\n\n# What are the types of classification?\n\n### There are 4 types of classification:\n\n1. Binary Classification: This method of classification is only used in cases where there are two exclusive categories to sort data into. The data is labeled as either 0 or 1 based on the category it falls into. A popular example of this is spam detection; a message is either labeled as spam or not spam. \n2. Multi-Class Classification: This method is used in cases where there are more than two class labels. Many binary classification algorithms can also be used for multi-class classification.\n3. Multi-Label Classification: In some cases, we may want multiple labels predicted for a data point. Multi-Class classification is capable of this. \n4. Imbalanced Classification: This method is useful in detecting outliers as a majority of samples in the training dataset belong to a “normal” class and a smaller minority belongs to an “outlier” class. This approach can be used for fraud detection and medical diagnosis tests.\n\n# What are some examples of classification?\n\n* Healthcare: Classification models have been used to predict if a person has a certain disease\n* Education: Classification can be used to organize documents by category or analyze student feedback on their professors\n* Transportation: Classification can determine which locations will have a rise in traffic, as well as predict issues that can occur in a location based on the weather conditions\n\n## Code Example\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# First we will load the dataset we will be using.\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\n\n# This data contains the measurements of different attributes of wines grown by three different cultivators in Italy.\n# Our decision tree will be able to determine which category it belongs in based on the given measurements.\nwine = load_wine()\nX = wine.data\ny = wine.target\n\n# load the dataframe\ndf = pd.DataFrame(wine.data, columns = wine.feature_names)\n\n# add labels\ndf['label'] = wine.target\n\n# Let's get a preview of what the data looks like\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Let's split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a Decision Tree classifier\nmodel = DecisionTreeClassifier(random_state=42)\n\n# Training\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Determine accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.94\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n\n# Let's generate a visualization of what the model looks like\nplt.figure(figsize=(12, 8))\nplot_tree(model, feature_names=wine.feature_names, class_names=wine.target_names.tolist(), filled=True, rounded=True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-4-output-1.png){width=912 height=611}\n:::\n:::\n\n\n",
    "supporting": [
      "post_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}