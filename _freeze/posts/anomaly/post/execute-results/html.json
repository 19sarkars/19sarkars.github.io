{
  "hash": "fbf19086f599ca384686498f604fbd40",
  "result": {
    "markdown": "---\ntitle: 'Anomaly/Outlier Detection'\nauthor: 'Shivangi Sarkar'\ndate: '2023-11-21'\ncategories: ['Anomaly detection']\ndescription: 'An introduction to anomaly/outlier detection in machine learning.'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n# What is anomaly detection?\n\nAnomaly detection is a process that is very commonly found in todayâ€™s world. It is the process of detecting data points that are outliers, or fall outside the normal range. \n\n# What are the types of outliers?\n\n### There are 3 types of outliers:\n\n1. Global outliers: These are outliers that are outside the range of all the other points in a dataset\n2. Contextual outliers: These deviate from other points in a specific area or context\n3. Collective outliers: These are groups of data points that deviate from the normal range.\n\n# What are the weaknesses of anomaly detection?\n\n* Poor data quality can affect the performance of anomaly detection\n* The anomaly detection algorithm itself can be poor and result in false alarms\n* Developing a baseline that accounts for normal patterns that occur less frequently such as heat waves or cold fronts.\n\n# What are some examples of applications using anomaly detection?\n\n* Cybersecurity: Anomaly detection is capable of detecting changes in access requests and traffic\n* Finance: Fraud can be detected by monitoring various factors such as the size of transactions, spending rate, location, and time\n* Healthcare: Anomaly detection can be used to monitor disease rates and detect outbreaks ahead of time\n\n## Code Example\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\n\n# Generate a one-dimensional dataset with anomalies\nnp.random.seed(42)\nnormal_data = np.random.normal(loc=0, scale=1, size=1000)\nanomalies = np.concatenate([normal_data, np.random.normal(loc=10, scale=1, size=10)])\n\n# Reshape the data to a column vector\ndata = anomalies.reshape(-1, 1)\n\n# Fit the Isolation Forest model\nclf = IsolationForest(contamination=0.01, random_state=42)  # Contamination is the expected proportion of outliers\nclf.fit(data)\n\n# Predict the anomalies\npredictions = clf.predict(data)\n\n# Visualize the results\nplt.scatter(range(len(data)), data, c=np.where(predictions == -1, 'red', 'blue'))\nplt.xlabel('Data Point Index')\nplt.ylabel('Value')\nplt.title('Anomaly Detection with Isolation Forest')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-2-output-1.png){width=587 height=449}\n:::\n:::\n\n\n1. We generate a one-dimensional dataset with normal data points and a few anomalies.\n2. We reshape the data to a column vector as scikit-learn's Isolation Forest expects a 2D array.\n3. We fit an Isolation Forest model to the data, specifying the contamination parameter to indicate the expected proportion of outliers.\n5. We predict whether each data point is an anomaly or not.\n6. We visualize the data points, coloring anomalies in red.\n\n",
    "supporting": [
      "post_files"
    ],
    "filters": [],
    "includes": {}
  }
}